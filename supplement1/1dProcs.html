<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>

<head>

	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <!--<meta name="generator" content="MATLAB 9.7">-->
	<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
	<meta name="DC.date" content="2020-08-12"><meta name="DC.source" content="checkXcorr.m">
	<link rel="stylesheet" type="text/css" href="../matlab.css" /> 	  
	<link rel="stylesheet" type="text/css" href="../mainPage.css" />

	<title>Supplement 1:  Correlated Random Draws</title>

	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	
	<script>
		window.MathJax = {
		  tex: {
			tags: 'ams'
		  }
		};
	</script>

</head>

<body>
	<div class="header">
	<table>
		<tr>
		<td align="left" align="140">
			<img class="bookImg" src="../PM199-245.jpg" />
		</td>
		<td align=center>
		<h1>Supplement 1:  Correlated Random Draws with Gaussian PDF</h1>
		</td>
		</table>
	</div>

	<div class="text">
		<!-- Vertical navigation bar on right side -->
		<div id="right_nav_box">
			<ul>
				<li><a href="../index.html">Home</a>
				<li><a href="../chapter1/index.html">Chapter 1</a>
				<li><a href="../chapter2/index.html">Chapter 2</a>
				<li><a href="../chapter3/index.html">Chapter 3</a>
				<li><a href="../chapter4/index.html">Chapter 4</a>
				<li><a href="../chapter5/index.html">Chapter 5</a>
				<li><a href="../chapter6/index.html">Chapter 6</a>
				<li><a href="../chapter7/index.html">Chapter 7</a>
				<li><a href="../chapter8/index.html">Chapter 8</a>
				<li><a href="../chapter9/index.html">Chapter 9</a>
			</ul>
		</div>

		<h1>1-D Processes</h1>
		<p>
		It can be useful to generate random draws of correlated processes. These can provide an input with known statistics for sensor models, estimation algorithms, control systems, etc. This article provides an introduction to the process, which also serves as background for generating phase screens, as described in Section 9.3. In particular, this article focuses on one-dimensional (<abbr title = "One-Dimensional">1-D</abbr>) processes with 
		a Gaussian probability density function (<abbr title = "Probability Density Function">PDF</abbr>).
		</p>
		
		<h2>Real-Valued Gaussian Random Variables</h2>
		<!--
		Start with real and transition to complex
		independent Gaussian Random variables are also uncorrelated
		-->
		
		<h3>Independent Gaussian Random Variables</h3>
		<p>
		Let \(u_i\) be one variable from a set of \(N\) <dfn>independent random variables</dfn> with a Gaussian <abbr title = "Probability Density Function">PDF</abbr> given by
		$$
		\begin{equation}
			p\left(u_i\right) = \frac{1}{\sqrt{2 \pi \sigma_{ui}^2}} \exp\left[-\frac{\left(u_i-\mu_{ui}\right)^2}{2\sigma_{ui}^2}\right],
		\end{equation}
		$$
		where \(\mu_{ui}\) is the set of \(N\) mean values and \(\sigma_{ui}^2\) is the set of \(N\) variances. The \(N^{th}\)-order joint <abbr title = "Probability Density Function">PDF</abbr> of all of the \(u_i\) is product of individual <abbr title = "Probability Density Functions">PDFs</abbr> given by
		$$
		\begin{equation}
		    p\left(u_1, u_2, \ldots, u_N\right) = \prod\limits_i^N p\left(u_i\right).
		\end{equation}
		$$
		</p>
		
		<h3>Correlated Gaussian Random Variables</h3>
		<p>
		Let \(v_i\) be a set of \(N\) <dfn>correlated random variables</dfn>, and denote all of the \(v_i\) as a column vector \(\mathbf{v}\). It has a vector of mean values \(\mathbf{\mu}_{v}\). The elements of the covariance matrix are given by
		$$
		\begin{equation}
		    C_{ij} = \left\langle \left(v_i - \mu_{vi}\right)\left(v_j - \mu_{vj}\right)\right\rangle.
		\end{equation}
		$$
		With these definitions, the \(N^{th}\)-order joint <abbr title = "Probability Density Function">PDF</abbr> of all of the \(v_i\) (or the vector \(\mathbf{v}\)) is
		$$
		\begin{equation}
			p\left(\mathbf{v}\right) = \frac{1}{\left(2\pi\right)^{N/2} \left\vert \mathbf{C} \right\vert^{1/2}} \exp\left[-\frac{1}{2}\left(\mathbf{v}-\mathbf{\mu}_v\right)^t \mathbf{C}^{-1}\left(\mathbf{v}-\mathbf{\mu}_v\right)\right].
		\end{equation}
		$$
		</p>
		
		<h2>Complex-Valued Gaussian Random Variables</h2>
		
		<h2>Sums of Gaussian Random Variables</h2>
		<p>
		Gaussian random variables have the property that weighted sums of Gaussian variables still have a Gaussian <abbr title = "Probability Density Function">PDF</abbr>. For example, let \(a_i\) be a set of \(N\) fixed numbers. Then, the sum
		$$
		\begin{equation}
			w = \sum\limits_{i=i}^N a_i u_i,
		\end{equation}
		$$
		also has a Gaussian <abbr title = "Probability Density Function">PDF</abbr> given by
		$$
		\begin{equation}
			p\left(w\right) = \frac{1}{\sqrt{2 \pi \sigma_w^2}} \exp\left[-\frac{\left(w-\mu_w\right)^2}{2\sigma_w^2}\right]
		\end{equation}.
		$$
		In this equation, the \(w\) parameters are related to the \(u_i\) parameters acccording to
		$$
		\begin{align}
		    \mu_w = \sum\limits_{i=1}^N a_i \mu_i \\
			\sigma_w^2 = \sum\limits_{i=1}^N a_i \sigma_{ui}^2.
		\end{align}
		$$
		</p>
		<!--
		<p>
		This property extends to a set of \(N\) random values \(v_i\).  with covariance matrix of \(u_i\), \(\sum_u\)
		</p>
		
		<p>
		Joint PDF for two correlated random variables. Example of generating two correlated random variables.
		</p>
		
		<p>
		Joint PDF for \(N\) correlated random variables. R and W method with Cholesky decomposition.
		</p>

		<p>
		If we know the covariance, we also know the PSD, In optical turbulence, we most often know the PSD, so focus on this method. Explain in terms of code. Show example usage with plots of PDF, mean, and covariance.
		</p>
		-->
		<h2>References</h2>
		<ol>
			<li>Joseph W. Goodman, <u>Statistical Optics</u> Ch. 3, Wiley, New York, NY (1985)</li>
		</ol>
	</div>

	<div class="footer">
		<br/>
		<hr/>
		<a href="../index.html">Home</a> | <a href="../aboutBook.html">About</a>
	</div>

</body>
</html>